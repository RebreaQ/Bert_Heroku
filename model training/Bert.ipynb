{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "diploma.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RebreaQ/Bert_news/blob/main/diploma.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2021-10-24T05:24:04.165001Z",
          "iopub.execute_input": "2021-10-24T05:24:04.165570Z",
          "iopub.status.idle": "2021-10-24T05:24:04.279574Z",
          "shell.execute_reply.started": "2021-10-24T05:24:04.165474Z",
          "shell.execute_reply": "2021-10-24T05:24:04.278898Z"
        },
        "trusted": true,
        "id": "kM5aOGickI5T",
        "outputId": "7e6aaf18-db0c-42d6-9010-820acf6c7c27"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "/kaggle/input/h1-ml1/article_metadata.hd5\n/kaggle/input/h1-ml1/val_scores.hd5\n/kaggle/input/h1-ml1/main_dev_sample.hd5\n/kaggle/input/h1-ml1/targets.hd5\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T05:24:11.252985Z",
          "iopub.execute_input": "2021-10-24T05:24:11.253298Z",
          "iopub.status.idle": "2021-10-24T05:24:16.917472Z",
          "shell.execute_reply.started": "2021-10-24T05:24:11.253246Z",
          "shell.execute_reply": "2021-10-24T05:24:16.916710Z"
        },
        "trusted": true,
        "id": "nuoCkA8QkI5W",
        "outputId": "54d1107f-9fb2-4162-bcdf-2e82cbd3e272"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "2021-10-24 05:24:11.752697: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Found GPU at: /device:GPU:0\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "2021-10-24 05:24:15.370556: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2021-10-24 05:24:15.373268: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2021-10-24 05:24:15.376278: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n2021-10-24 05:24:15.421350: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-10-24 05:24:15.422026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \npciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\ncoreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n2021-10-24 05:24:15.422068: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2021-10-24 05:24:15.455457: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2021-10-24 05:24:15.455536: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n2021-10-24 05:24:15.470034: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n2021-10-24 05:24:15.478120: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n2021-10-24 05:24:15.502438: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n2021-10-24 05:24:15.509249: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n2021-10-24 05:24:15.512762: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n2021-10-24 05:24:15.512941: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-10-24 05:24:15.513619: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-10-24 05:24:15.514990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n2021-10-24 05:24:15.515690: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2021-10-24 05:24:16.903719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n2021-10-24 05:24:16.903772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n2021-10-24 05:24:16.903783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n2021-10-24 05:24:16.906070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-10-24 05:24:16.906757: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-10-24 05:24:16.907463: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-10-24 05:24:16.908043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/device:GPU:0 with 14957 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T05:24:16.919269Z",
          "iopub.execute_input": "2021-10-24T05:24:16.919563Z",
          "iopub.status.idle": "2021-10-24T05:24:21.236960Z",
          "shell.execute_reply.started": "2021-10-24T05:24:16.919526Z",
          "shell.execute_reply": "2021-10-24T05:24:21.235543Z"
        },
        "trusted": true,
        "id": "nbF9fZ2NkI5Y",
        "outputId": "b2e74304-6ed4-4741-839b-5a6935cfc0a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "There are 1 GPU(s) available.\nWe will use the GPU: Tesla P100-PCIE-16GB\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "article_metadata = pd.read_hdf(\"/kaggle/input/h1-ml1/article_metadata.hd5\")\n",
        "targets = pd.read_hdf(\"/kaggle/input/h1-ml1/targets.hd5\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T05:24:21.238478Z",
          "iopub.execute_input": "2021-10-24T05:24:21.239039Z",
          "iopub.status.idle": "2021-10-24T05:24:39.291706Z",
          "shell.execute_reply.started": "2021-10-24T05:24:21.239000Z",
          "shell.execute_reply": "2021-10-24T05:24:39.290972Z"
        },
        "trusted": true,
        "id": "sVlb0_Z2kI5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article_metadata"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T05:24:39.294345Z",
          "iopub.execute_input": "2021-10-24T05:24:39.295201Z",
          "iopub.status.idle": "2021-10-24T05:24:39.329952Z",
          "shell.execute_reply.started": "2021-10-24T05:24:39.295161Z",
          "shell.execute_reply": "2021-10-24T05:24:39.329139Z"
        },
        "trusted": true,
        "id": "xXbCRhcskI5Z",
        "outputId": "3823eb69-f2f1-4531-a236-1bb2483e4abc"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                                    title  \\\n0       Biden assails Trump for 'bald-faced lies' abou...   \n1       NexPoint Strategic Opportunities Fund Declares...   \n2       Kayne Anderson MLP/Midstream Investment Compan...   \n3       Kayne Anderson Midstream/Energy Fund Provides ...   \n4         Canopy by Hilton Opens in Heart of Philadelphia   \n...                                                   ...   \n962743  ImmVira's MVR-C5252 Targeting Brain Tumor Obta...   \n962744  Stalled Stimulus Leaves Indonesia’s Small Firm...   \n962745  The Trustees of Columbia University in the Cit...   \n962746  The Trustees of Columbia University in the Cit...   \n962747  Epizyme and HUTCHMED Announce Strategic Collab...   \n\n                                              description  \\\n0       Democratic presidential candidate Joe Biden sa...   \n1       NexPoint Strategic Opportunities Fund (NYSE: N...   \n2       HOUSTON, Aug. 03, 2020 (GLOBE NEWSWIRE) -- Kay...   \n3       HOUSTON, Aug. 03, 2020 (GLOBE NEWSWIRE) -- Kay...   \n4       Canopy by Hilton today opened Canopy by Hilton...   \n...                                                   ...   \n962743  SHENZHEN, China, Aug. 8, 2021 /PRNewswire/ -- ...   \n962744                                                      \n962745                                                      \n962746                                                      \n962747  Collaboration designed to accelerate global de...   \n\n                             source.name      symbols  \\\n0                                Reuters           []   \n1                            PR Newswire        [NHF]   \n2                          GlobeNewswire        [KYN]   \n3                          GlobeNewswire        [KMF]   \n4                            PR Newswire        [HLT]   \n...                                  ...          ...   \n962743                       PR Newswire           []   \n962744                         Bloomberg           []   \n962745  US Patent Trial and Appeal Board       [ILMN]   \n962746  US Patent Trial and Appeal Board       [ILMN]   \n962747                      BusinessWire  [EPZM, HCM]   \n\n                                         industries               sectors  \\\n0                                                []                    []   \n1                                [Asset Management]  [Financial Services]   \n2                                [Asset Management]  [Financial Services]   \n3                                                []                    []   \n4                                         [Lodging]   [Consumer Cyclical]   \n...                                             ...                   ...   \n962743                                           []                    []   \n962744                                           []                    []   \n962745                     [Diagnostics & Research]          [Healthcare]   \n962746                     [Diagnostics & Research]          [Healthcare]   \n962747  [Biotechnology, Drug Manufacturers - Major]          [Healthcare]   \n\n       time zone                           news_id  \n0          UTC 0  8557db1542d25f5d274fec9e35a8929c  \n1          UTC 0  f1db5f23dfc994334edd5cf8a0965ab5  \n2          UTC 0  d6ee12389a83b34859591c56286ac3b5  \n3          UTC 0  dd631c50be0c7b03af18ed63cad9182f  \n4          UTC 0  48f2e18d471abbc70fad3a229d84c351  \n...          ...                               ...  \n962743     UTC 0  36f8da89d343b5bf653388e1b97c7347  \n962744     UTC 0  685ad25f14a623e7ab7754dafb5b2fcf  \n962745     UTC 0  f27fec2cc6441002545c62811a152a57  \n962746     UTC 0  98da885feb554583b6ad846aaa6bd173  \n962747     UTC 0  738de9ba95d2799d088485bbf9c918b5  \n\n[962748 rows x 8 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>description</th>\n      <th>source.name</th>\n      <th>symbols</th>\n      <th>industries</th>\n      <th>sectors</th>\n      <th>time zone</th>\n      <th>news_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Biden assails Trump for 'bald-faced lies' abou...</td>\n      <td>Democratic presidential candidate Joe Biden sa...</td>\n      <td>Reuters</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>UTC 0</td>\n      <td>8557db1542d25f5d274fec9e35a8929c</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NexPoint Strategic Opportunities Fund Declares...</td>\n      <td>NexPoint Strategic Opportunities Fund (NYSE: N...</td>\n      <td>PR Newswire</td>\n      <td>[NHF]</td>\n      <td>[Asset Management]</td>\n      <td>[Financial Services]</td>\n      <td>UTC 0</td>\n      <td>f1db5f23dfc994334edd5cf8a0965ab5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Kayne Anderson MLP/Midstream Investment Compan...</td>\n      <td>HOUSTON, Aug. 03, 2020 (GLOBE NEWSWIRE) -- Kay...</td>\n      <td>GlobeNewswire</td>\n      <td>[KYN]</td>\n      <td>[Asset Management]</td>\n      <td>[Financial Services]</td>\n      <td>UTC 0</td>\n      <td>d6ee12389a83b34859591c56286ac3b5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Kayne Anderson Midstream/Energy Fund Provides ...</td>\n      <td>HOUSTON, Aug. 03, 2020 (GLOBE NEWSWIRE) -- Kay...</td>\n      <td>GlobeNewswire</td>\n      <td>[KMF]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>UTC 0</td>\n      <td>dd631c50be0c7b03af18ed63cad9182f</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Canopy by Hilton Opens in Heart of Philadelphia</td>\n      <td>Canopy by Hilton today opened Canopy by Hilton...</td>\n      <td>PR Newswire</td>\n      <td>[HLT]</td>\n      <td>[Lodging]</td>\n      <td>[Consumer Cyclical]</td>\n      <td>UTC 0</td>\n      <td>48f2e18d471abbc70fad3a229d84c351</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>962743</th>\n      <td>ImmVira's MVR-C5252 Targeting Brain Tumor Obta...</td>\n      <td>SHENZHEN, China, Aug. 8, 2021 /PRNewswire/ -- ...</td>\n      <td>PR Newswire</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>UTC 0</td>\n      <td>36f8da89d343b5bf653388e1b97c7347</td>\n    </tr>\n    <tr>\n      <th>962744</th>\n      <td>Stalled Stimulus Leaves Indonesia’s Small Firm...</td>\n      <td></td>\n      <td>Bloomberg</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>UTC 0</td>\n      <td>685ad25f14a623e7ab7754dafb5b2fcf</td>\n    </tr>\n    <tr>\n      <th>962745</th>\n      <td>The Trustees of Columbia University in the Cit...</td>\n      <td></td>\n      <td>US Patent Trial and Appeal Board</td>\n      <td>[ILMN]</td>\n      <td>[Diagnostics &amp; Research]</td>\n      <td>[Healthcare]</td>\n      <td>UTC 0</td>\n      <td>f27fec2cc6441002545c62811a152a57</td>\n    </tr>\n    <tr>\n      <th>962746</th>\n      <td>The Trustees of Columbia University in the Cit...</td>\n      <td></td>\n      <td>US Patent Trial and Appeal Board</td>\n      <td>[ILMN]</td>\n      <td>[Diagnostics &amp; Research]</td>\n      <td>[Healthcare]</td>\n      <td>UTC 0</td>\n      <td>98da885feb554583b6ad846aaa6bd173</td>\n    </tr>\n    <tr>\n      <th>962747</th>\n      <td>Epizyme and HUTCHMED Announce Strategic Collab...</td>\n      <td>Collaboration designed to accelerate global de...</td>\n      <td>BusinessWire</td>\n      <td>[EPZM, HCM]</td>\n      <td>[Biotechnology, Drug Manufacturers - Major]</td>\n      <td>[Healthcare]</td>\n      <td>UTC 0</td>\n      <td>738de9ba95d2799d088485bbf9c918b5</td>\n    </tr>\n  </tbody>\n</table>\n<p>962748 rows × 8 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T05:24:39.331243Z",
          "iopub.execute_input": "2021-10-24T05:24:39.331572Z",
          "iopub.status.idle": "2021-10-24T05:24:39.647644Z",
          "shell.execute_reply.started": "2021-10-24T05:24:39.331538Z",
          "shell.execute_reply": "2021-10-24T05:24:39.646968Z"
        },
        "trusted": true,
        "id": "Q1drDrvukI5a",
        "outputId": "8a20d047-1f1a-4bfd-a066-27d2d075d333"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "        3_False_0.02  3_False_0.04  3_False_0.05  3_False_0.07  3_False_0.1  \\\n0                NaN           NaN           NaN           NaN          NaN   \n1                NaN           NaN           NaN           NaN          NaN   \n2                NaN           NaN           NaN           NaN          NaN   \n3                NaN           NaN           NaN           NaN          NaN   \n4                0.0           0.0           0.0           0.0          0.0   \n...              ...           ...           ...           ...          ...   \n866162           NaN           NaN           NaN           NaN          NaN   \n866163           NaN           NaN           NaN           NaN          NaN   \n866164           NaN           NaN           NaN           NaN          NaN   \n866165           NaN           NaN           NaN           NaN          NaN   \n866166           NaN           NaN           NaN           NaN          NaN   \n\n        3_False_0.15  3_True_0.02  3_True_0.04  3_True_0.05  3_True_0.07  ...  \\\n0                NaN          NaN          NaN          NaN          NaN  ...   \n1                NaN          NaN          NaN          NaN          NaN  ...   \n2                NaN          NaN          NaN          NaN          NaN  ...   \n3                NaN          NaN          NaN          NaN          NaN  ...   \n4                0.0          0.0          0.0          0.0          0.0  ...   \n...              ...          ...          ...          ...          ...  ...   \n866162           NaN          NaN          NaN          NaN          NaN  ...   \n866163           NaN          NaN          NaN          NaN          NaN  ...   \n866164           NaN          NaN          NaN          NaN          NaN  ...   \n866165           NaN          NaN          NaN          NaN          NaN  ...   \n866166           NaN          NaN          NaN          NaN          NaN  ...   \n\n        15_False_0.1  15_False_0.15  15_True_0.02  15_True_0.04  15_True_0.05  \\\n0                NaN            NaN           NaN           NaN           NaN   \n1                NaN            NaN           NaN           NaN           NaN   \n2                NaN            NaN           NaN           NaN           NaN   \n3                NaN            NaN           NaN           NaN           NaN   \n4                0.0            0.0           0.0           0.0           0.0   \n...              ...            ...           ...           ...           ...   \n866162           NaN            NaN           NaN           NaN           NaN   \n866163           NaN            NaN           NaN           NaN           NaN   \n866164           NaN            NaN           NaN           NaN           NaN   \n866165           NaN            NaN           NaN           NaN           NaN   \n866166           NaN            NaN           NaN           NaN           NaN   \n\n        15_True_0.07  15_True_0.1  15_True_0.15  \\\n0                NaN          NaN           NaN   \n1                NaN          NaN           NaN   \n2                NaN          NaN           NaN   \n3                NaN          NaN           NaN   \n4                0.0          0.0           0.0   \n...              ...          ...           ...   \n866162           NaN          NaN           NaN   \n866163           NaN          NaN           NaN   \n866164           NaN          NaN           NaN   \n866165           NaN          NaN           NaN   \n866166           NaN          NaN           NaN   \n\n                                 news_id  ticker  \n0       f1db5f23dfc994334edd5cf8a0965ab5     NHF  \n1       d6ee12389a83b34859591c56286ac3b5     KYN  \n2       dd631c50be0c7b03af18ed63cad9182f     KMF  \n3       48f2e18d471abbc70fad3a229d84c351     HLT  \n4       b65b908409773fd7a7fb489aafb8c547    MSFT  \n...                                  ...     ...  \n866162  128bb8932be351af615e79b2a4ab6964    ILMN  \n866163  f27fec2cc6441002545c62811a152a57    ILMN  \n866164  98da885feb554583b6ad846aaa6bd173    ILMN  \n866165  738de9ba95d2799d088485bbf9c918b5    EPZM  \n866166  738de9ba95d2799d088485bbf9c918b5     HCM  \n\n[866167 rows x 62 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>3_False_0.02</th>\n      <th>3_False_0.04</th>\n      <th>3_False_0.05</th>\n      <th>3_False_0.07</th>\n      <th>3_False_0.1</th>\n      <th>3_False_0.15</th>\n      <th>3_True_0.02</th>\n      <th>3_True_0.04</th>\n      <th>3_True_0.05</th>\n      <th>3_True_0.07</th>\n      <th>...</th>\n      <th>15_False_0.1</th>\n      <th>15_False_0.15</th>\n      <th>15_True_0.02</th>\n      <th>15_True_0.04</th>\n      <th>15_True_0.05</th>\n      <th>15_True_0.07</th>\n      <th>15_True_0.1</th>\n      <th>15_True_0.15</th>\n      <th>news_id</th>\n      <th>ticker</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>f1db5f23dfc994334edd5cf8a0965ab5</td>\n      <td>NHF</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>d6ee12389a83b34859591c56286ac3b5</td>\n      <td>KYN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>dd631c50be0c7b03af18ed63cad9182f</td>\n      <td>KMF</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>48f2e18d471abbc70fad3a229d84c351</td>\n      <td>HLT</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>b65b908409773fd7a7fb489aafb8c547</td>\n      <td>MSFT</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>866162</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>128bb8932be351af615e79b2a4ab6964</td>\n      <td>ILMN</td>\n    </tr>\n    <tr>\n      <th>866163</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>f27fec2cc6441002545c62811a152a57</td>\n      <td>ILMN</td>\n    </tr>\n    <tr>\n      <th>866164</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>98da885feb554583b6ad846aaa6bd173</td>\n      <td>ILMN</td>\n    </tr>\n    <tr>\n      <th>866165</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>738de9ba95d2799d088485bbf9c918b5</td>\n      <td>EPZM</td>\n    </tr>\n    <tr>\n      <th>866166</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>738de9ba95d2799d088485bbf9c918b5</td>\n      <td>HCM</td>\n    </tr>\n  </tbody>\n</table>\n<p>866167 rows × 62 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=article_metadata.join(targets.set_index('news_id'), on='news_id')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T05:24:42.313464Z",
          "iopub.execute_input": "2021-10-24T05:24:42.313743Z",
          "iopub.status.idle": "2021-10-24T05:24:44.027456Z",
          "shell.execute_reply.started": "2021-10-24T05:24:42.313712Z",
          "shell.execute_reply": "2021-10-24T05:24:44.026713Z"
        },
        "trusted": true,
        "id": "0dyh5xlNkI5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.dropna()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T05:24:44.028792Z",
          "iopub.execute_input": "2021-10-24T05:24:44.029069Z",
          "iopub.status.idle": "2021-10-24T05:24:46.436325Z",
          "shell.execute_reply.started": "2021-10-24T05:24:44.029035Z",
          "shell.execute_reply": "2021-10-24T05:24:46.435537Z"
        },
        "trusted": true,
        "id": "TBQaIXCqkI5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df[['title', '10_True_0.05']]\n",
        "df.rename(columns = {'title' : 'title', '10_True_0.05' : 'lables'}, inplace = True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T05:24:54.745959Z",
          "iopub.execute_input": "2021-10-24T05:24:54.746216Z",
          "iopub.status.idle": "2021-10-24T05:24:54.801868Z",
          "shell.execute_reply.started": "2021-10-24T05:24:54.746188Z",
          "shell.execute_reply": "2021-10-24T05:24:54.801175Z"
        },
        "trusted": true,
        "id": "Rzp466UzkI5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['lables'] = df['lables'].astype(int)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T05:24:55.133285Z",
          "iopub.execute_input": "2021-10-24T05:24:55.133886Z",
          "iopub.status.idle": "2021-10-24T05:24:55.142989Z",
          "shell.execute_reply.started": "2021-10-24T05:24:55.133851Z",
          "shell.execute_reply": "2021-10-24T05:24:55.142190Z"
        },
        "trusted": true,
        "id": "Ucphsa-tkI5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "title = df['title'].map(lambda x: re.sub('[^a-zA-Z0-9 .,]|(?<!\\\\d)[.,]|[.,](?!\\\\d)', '',x))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T05:24:57.377559Z",
          "iopub.execute_input": "2021-10-24T05:24:57.378392Z",
          "iopub.status.idle": "2021-10-24T05:25:05.322148Z",
          "shell.execute_reply.started": "2021-10-24T05:24:57.378342Z",
          "shell.execute_reply": "2021-10-24T05:25:05.321402Z"
        },
        "trusted": true,
        "id": "585dMpPIkI5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['title']=title.apply(lambda x: x.lower())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T05:25:05.323756Z",
          "iopub.execute_input": "2021-10-24T05:25:05.324034Z",
          "iopub.status.idle": "2021-10-24T05:25:05.531677Z",
          "shell.execute_reply.started": "2021-10-24T05:25:05.324000Z",
          "shell.execute_reply": "2021-10-24T05:25:05.530962Z"
        },
        "trusted": true,
        "id": "i9C7HSvmkI5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T05:25:05.532932Z",
          "iopub.execute_input": "2021-10-24T05:25:05.533179Z",
          "iopub.status.idle": "2021-10-24T05:25:05.545521Z",
          "shell.execute_reply.started": "2021-10-24T05:25:05.533147Z",
          "shell.execute_reply": "2021-10-24T05:25:05.544877Z"
        },
        "trusted": true,
        "id": "a75M9ikTkI5f",
        "outputId": "161bb4d4-7fdf-4cb3-fb61-3b50770dd398"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                                    title  lables\n5       global marketsasia stocks rise as upbeat facto...       0\n6       asia shares set to gain after manufacturing da...       0\n11      blizzard workers share salaries in revolt over...       0\n12      kessler topaz meltzer  check llp  deadline rem...       0\n18      trump seeks tiktok payment to us despite no cl...       0\n...                                                   ...     ...\n962426               earnings scheduled for august 9 2021       0\n962426               earnings scheduled for august 9 2021       0\n962428  pinduoduo launches 2021 smart agriculture comp...       0\n962438  alibaba sacks manager accused of sexually assa...       0\n962443  biontech se bntx q2 2021 earnings call transcript       0\n\n[485712 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>lables</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5</th>\n      <td>global marketsasia stocks rise as upbeat facto...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>asia shares set to gain after manufacturing da...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>blizzard workers share salaries in revolt over...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>kessler topaz meltzer  check llp  deadline rem...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>trump seeks tiktok payment to us despite no cl...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>962426</th>\n      <td>earnings scheduled for august 9 2021</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>962426</th>\n      <td>earnings scheduled for august 9 2021</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>962428</th>\n      <td>pinduoduo launches 2021 smart agriculture comp...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>962438</th>\n      <td>alibaba sacks manager accused of sexually assa...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>962443</th>\n      <td>biontech se bntx q2 2021 earnings call transcript</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>485712 rows × 2 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T05:25:16.962241Z",
          "iopub.execute_input": "2021-10-24T05:25:16.963006Z",
          "iopub.status.idle": "2021-10-24T05:25:17.118190Z",
          "shell.execute_reply.started": "2021-10-24T05:25:16.962962Z",
          "shell.execute_reply": "2021-10-24T05:25:17.117448Z"
        },
        "trusted": true,
        "id": "vg_HQmSjkI5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(df, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T05:25:51.601309Z",
          "iopub.execute_input": "2021-10-24T05:25:51.601855Z",
          "iopub.status.idle": "2021-10-24T05:25:52.184479Z",
          "shell.execute_reply.started": "2021-10-24T05:25:51.601817Z",
          "shell.execute_reply": "2021-10-24T05:25:52.183724Z"
        },
        "trusted": true,
        "id": "kXdNkSfYkI5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "title = df.title.values\n",
        "labels = df.lables.values"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T05:25:58.474250Z",
          "iopub.execute_input": "2021-10-24T05:25:58.474580Z",
          "iopub.status.idle": "2021-10-24T05:25:58.499024Z",
          "shell.execute_reply.started": "2021-10-24T05:25:58.474547Z",
          "shell.execute_reply": "2021-10-24T05:25:58.497440Z"
        },
        "trusted": true,
        "id": "L_k5SNFXkI5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForPreTraining\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T05:26:00.141152Z",
          "iopub.execute_input": "2021-10-24T05:26:00.141439Z",
          "iopub.status.idle": "2021-10-24T05:26:04.901534Z",
          "shell.execute_reply.started": "2021-10-24T05:26:00.141409Z",
          "shell.execute_reply": "2021-10-24T05:26:04.900883Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "6e259bbb8faa4e2eb13da113fda43bac",
            "ede53b230cbb44d2b94aac2c5f85c78b",
            "900f5c0e0c93471392ad03ff26ae9303"
          ]
        },
        "id": "Pt7da6O1kI5g",
        "outputId": "f9c59238-4788-4a56-ce7c-df4003aa85d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e259bbb8faa4e2eb13da113fda43bac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ede53b230cbb44d2b94aac2c5f85c78b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "900f5c0e0c93471392ad03ff26ae9303"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(' Original: ', title[2])\n",
        "print('Tokenized: ', tokenizer.tokenize(title[2]))\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(title[2])))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T05:27:52.942315Z",
          "iopub.execute_input": "2021-10-24T05:27:52.942578Z",
          "iopub.status.idle": "2021-10-24T05:27:52.949743Z",
          "shell.execute_reply.started": "2021-10-24T05:27:52.942548Z",
          "shell.execute_reply": "2021-10-24T05:27:52.949020Z"
        },
        "trusted": true,
        "id": "W6t1WNxxkI5h",
        "outputId": "4eb19e42-345d-4a25-a3dd-ab3dab119588"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": " Original:  blizzard workers share salaries in revolt over wage disparities\nTokenized:  ['blizzard', 'workers', 'share', 'salaries', 'in', 'revolt', 'over', 'wage', 'di', '##spar', '##ities']\nToken IDs:  [21689, 3667, 3745, 20566, 1999, 10073, 2058, 11897, 4487, 27694, 6447]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize Dataset"
      ],
      "metadata": {
        "id": "HTcXZMyUkI5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len = [len(i.split()) for i in df[\"title\"]]\n",
        "\n",
        "pd.Series(seq_len).hist(bins = 30)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T05:34:57.521677Z",
          "iopub.execute_input": "2021-10-24T05:34:57.522086Z",
          "iopub.status.idle": "2021-10-24T05:34:58.114549Z",
          "shell.execute_reply.started": "2021-10-24T05:34:57.522046Z",
          "shell.execute_reply": "2021-10-24T05:34:58.113827Z"
        },
        "trusted": true,
        "id": "N3MM448SkI5k",
        "outputId": "09bbdb4d-d575-49d2-bae5-be0814294eb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 29,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<AxesSubplot:>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for t in title:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        t,                     \n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 18,         # Pad & truncate all sentences.  \n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,  # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     \n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "    #Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T05:35:53.004499Z",
          "iopub.execute_input": "2021-10-24T05:35:53.004766Z",
          "iopub.status.idle": "2021-10-24T05:38:10.350747Z",
          "shell.execute_reply.started": "2021-10-24T05:35:53.004737Z",
          "shell.execute_reply": "2021-10-24T05:38:10.350002Z"
        },
        "trusted": true,
        "id": "eT_RjhdckI5k",
        "outputId": "46323d74-2bae-4b9b-9309-43154f17a0bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Original: ', title[3])\n",
        "print('Token IDs:', input_ids[3])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T05:38:59.977595Z",
          "iopub.execute_input": "2021-10-24T05:38:59.977870Z",
          "iopub.status.idle": "2021-10-24T05:38:59.985355Z",
          "shell.execute_reply.started": "2021-10-24T05:38:59.977841Z",
          "shell.execute_reply": "2021-10-24T05:38:59.984638Z"
        },
        "trusted": true,
        "id": "DnkSUgU0kI5l",
        "outputId": "c1a80912-a9cb-4b6b-e4f9-58e02cb97a86"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Original:  kessler topaz meltzer  check llp  deadline reminder for ideanomics inc investors\nToken IDs: tensor([  101, 17710, 23385,  2327, 10936, 14899,  6290,  4638,  2222,  2361,\n        15117, 14764,  2005,  2801,  3630, 22924,  4297,   102])\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Original: ', title[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T05:39:23.644214Z",
          "iopub.execute_input": "2021-10-24T05:39:23.644976Z",
          "iopub.status.idle": "2021-10-24T05:39:23.652976Z",
          "shell.execute_reply.started": "2021-10-24T05:39:23.644910Z",
          "shell.execute_reply": "2021-10-24T05:39:23.651873Z"
        },
        "trusted": true,
        "id": "OP5Q0_gvkI5m",
        "outputId": "cb601196-046c-444b-d936-20349ed47f83"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Original:  global marketsasia stocks rise as upbeat factory data lifts confidence\nToken IDs: tensor([  101,  3795,  6089, 15396, 15768,  4125,  2004, 27999,  4713,  2951,\n        13695,  7023,   102,     0,     0,     0,     0,     0])\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training & Validation Split"
      ],
      "metadata": {
        "id": "Fn7aadHAkI5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size=len(dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset  = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T05:40:27.389711Z",
          "iopub.execute_input": "2021-10-24T05:40:27.389996Z",
          "iopub.status.idle": "2021-10-24T05:40:27.417359Z",
          "shell.execute_reply.started": "2021-10-24T05:40:27.389964Z",
          "shell.execute_reply": "2021-10-24T05:40:27.416635Z"
        },
        "trusted": true,
        "id": "CN1p_6dwkI5m",
        "outputId": "22a37893-ab97-4ff2-9b46-6530ead49bc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "184,420 training samples\n46,106 validation samples\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  \n",
        "            sampler = RandomSampler(train_dataset), \n",
        "            batch_size = batch_size \n",
        "        )\n",
        "\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, \n",
        "            sampler = SequentialSampler(val_dataset), \n",
        "            batch_size = batch_size \n",
        "        )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T05:40:32.395318Z",
          "iopub.execute_input": "2021-10-24T05:40:32.395929Z",
          "iopub.status.idle": "2021-10-24T05:40:32.401263Z",
          "shell.execute_reply.started": "2021-10-24T05:40:32.395874Z",
          "shell.execute_reply": "2021-10-24T05:40:32.400346Z"
        },
        "trusted": true,
        "id": "g1UYel6AkI5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BertForSequenceClassification"
      ],
      "metadata": {
        "id": "f4VWErwykI5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", \n",
        "    num_labels = 2, \n",
        "                    \n",
        "    output_attentions = False, \n",
        "    output_hidden_states = False, \n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T05:40:41.548193Z",
          "iopub.execute_input": "2021-10-24T05:40:41.548460Z",
          "iopub.status.idle": "2021-10-24T05:41:01.455536Z",
          "shell.execute_reply.started": "2021-10-24T05:40:41.548432Z",
          "shell.execute_reply": "2021-10-24T05:41:01.454785Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "eaca4c248a4645c0abcd545d2ab9aec9",
            "e28ee2565ad84aacbbd19377edd8c43e"
          ]
        },
        "id": "VHt009V4kI5n",
        "outputId": "2e177ae2-f8fc-4c5a-99ef-dcdfc44f8555"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eaca4c248a4645c0abcd545d2ab9aec9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e28ee2565ad84aacbbd19377edd8c43e"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "execution_count": 40,
          "output_type": "execute_result",
          "data": {
            "text/plain": "BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimizer & Learning Rate Scheduler"
      ],
      "metadata": {
        "id": "NtYHC6awkI5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr =  1e-3, \n",
        "                  eps = 1e-8 \n",
        "                )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T05:41:01.457252Z",
          "iopub.execute_input": "2021-10-24T05:41:01.458037Z",
          "iopub.status.idle": "2021-10-24T05:41:01.465807Z",
          "shell.execute_reply.started": "2021-10-24T05:41:01.457999Z",
          "shell.execute_reply": "2021-10-24T05:41:01.465006Z"
        },
        "trusted": true,
        "id": "H28b7hzlkI5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "epochs = 2\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, \n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T05:41:03.201062Z",
          "iopub.execute_input": "2021-10-24T05:41:03.201628Z",
          "iopub.status.idle": "2021-10-24T05:41:03.206749Z",
          "shell.execute_reply.started": "2021-10-24T05:41:03.201590Z",
          "shell.execute_reply": "2021-10-24T05:41:03.205883Z"
        },
        "trusted": true,
        "id": "BT1ocV0mkI5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Loop"
      ],
      "metadata": {
        "id": "OKADQIFfkI5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T05:41:06.327299Z",
          "iopub.execute_input": "2021-10-24T05:41:06.327815Z",
          "iopub.status.idle": "2021-10-24T05:41:06.332827Z",
          "shell.execute_reply.started": "2021-10-24T05:41:06.327777Z",
          "shell.execute_reply": "2021-10-24T05:41:06.331748Z"
        },
        "trusted": true,
        "id": "l74UckAukI5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T05:41:07.953582Z",
          "iopub.execute_input": "2021-10-24T05:41:07.954379Z",
          "iopub.status.idle": "2021-10-24T05:41:07.960075Z",
          "shell.execute_reply.started": "2021-10-24T05:41:07.954331Z",
          "shell.execute_reply": "2021-10-24T05:41:07.958994Z"
        },
        "trusted": true,
        "id": "nJiYUZYvkI5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "total_t0 = time.time()\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        if step % 64 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "\n",
        "        output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "        loss = output.loss\n",
        "        logits = output.logits\n",
        "\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "\n",
        "        with torch.no_grad():        \n",
        "\n",
        "\n",
        "            output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "            loss = output.loss\n",
        "            logits = output.logits\n",
        "            \n",
        "\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T05:41:09.067732Z",
          "iopub.execute_input": "2021-10-24T05:41:09.068094Z",
          "iopub.status.idle": "2021-10-24T06:00:16.384541Z",
          "shell.execute_reply.started": "2021-10-24T05:41:09.068051Z",
          "shell.execute_reply": "2021-10-24T06:00:16.383654Z"
        },
        "trusted": true,
        "id": "J-jitHg6kI5p",
        "outputId": "3c8c7e66-a291-49ba-a8a4-0733e8337d95"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "\n======== Epoch 1 / 2 ========\nTraining...\n  Batch    64  of  5,764.    Elapsed: 0:00:07.\n  Batch   128  of  5,764.    Elapsed: 0:00:13.\n  Batch   192  of  5,764.    Elapsed: 0:00:19.\n  Batch   256  of  5,764.    Elapsed: 0:00:25.\n  Batch   320  of  5,764.    Elapsed: 0:00:31.\n  Batch   384  of  5,764.    Elapsed: 0:00:37.\n  Batch   448  of  5,764.    Elapsed: 0:00:43.\n  Batch   512  of  5,764.    Elapsed: 0:00:49.\n  Batch   576  of  5,764.    Elapsed: 0:00:55.\n  Batch   640  of  5,764.    Elapsed: 0:01:02.\n  Batch   704  of  5,764.    Elapsed: 0:01:08.\n  Batch   768  of  5,764.    Elapsed: 0:01:14.\n  Batch   832  of  5,764.    Elapsed: 0:01:20.\n  Batch   896  of  5,764.    Elapsed: 0:01:26.\n  Batch   960  of  5,764.    Elapsed: 0:01:32.\n  Batch 1,024  of  5,764.    Elapsed: 0:01:38.\n  Batch 1,088  of  5,764.    Elapsed: 0:01:44.\n  Batch 1,152  of  5,764.    Elapsed: 0:01:50.\n  Batch 1,216  of  5,764.    Elapsed: 0:01:56.\n  Batch 1,280  of  5,764.    Elapsed: 0:02:02.\n  Batch 1,344  of  5,764.    Elapsed: 0:02:09.\n  Batch 1,408  of  5,764.    Elapsed: 0:02:15.\n  Batch 1,472  of  5,764.    Elapsed: 0:02:21.\n  Batch 1,536  of  5,764.    Elapsed: 0:02:27.\n  Batch 1,600  of  5,764.    Elapsed: 0:02:33.\n  Batch 1,664  of  5,764.    Elapsed: 0:02:39.\n  Batch 1,728  of  5,764.    Elapsed: 0:02:45.\n  Batch 1,792  of  5,764.    Elapsed: 0:02:51.\n  Batch 1,856  of  5,764.    Elapsed: 0:02:57.\n  Batch 1,920  of  5,764.    Elapsed: 0:03:03.\n  Batch 1,984  of  5,764.    Elapsed: 0:03:09.\n  Batch 2,048  of  5,764.    Elapsed: 0:03:15.\n  Batch 2,112  of  5,764.    Elapsed: 0:03:21.\n  Batch 2,176  of  5,764.    Elapsed: 0:03:27.\n  Batch 2,240  of  5,764.    Elapsed: 0:03:33.\n  Batch 2,304  of  5,764.    Elapsed: 0:03:39.\n  Batch 2,368  of  5,764.    Elapsed: 0:03:45.\n  Batch 2,432  of  5,764.    Elapsed: 0:03:51.\n  Batch 2,496  of  5,764.    Elapsed: 0:03:57.\n  Batch 2,560  of  5,764.    Elapsed: 0:04:03.\n  Batch 2,624  of  5,764.    Elapsed: 0:04:09.\n  Batch 2,688  of  5,764.    Elapsed: 0:04:15.\n  Batch 2,752  of  5,764.    Elapsed: 0:04:21.\n  Batch 2,816  of  5,764.    Elapsed: 0:04:28.\n  Batch 2,880  of  5,764.    Elapsed: 0:04:33.\n  Batch 2,944  of  5,764.    Elapsed: 0:04:39.\n  Batch 3,008  of  5,764.    Elapsed: 0:04:45.\n  Batch 3,072  of  5,764.    Elapsed: 0:04:51.\n  Batch 3,136  of  5,764.    Elapsed: 0:04:57.\n  Batch 3,200  of  5,764.    Elapsed: 0:05:04.\n  Batch 3,264  of  5,764.    Elapsed: 0:05:10.\n  Batch 3,328  of  5,764.    Elapsed: 0:05:16.\n  Batch 3,392  of  5,764.    Elapsed: 0:05:22.\n  Batch 3,456  of  5,764.    Elapsed: 0:05:28.\n  Batch 3,520  of  5,764.    Elapsed: 0:05:34.\n  Batch 3,584  of  5,764.    Elapsed: 0:05:40.\n  Batch 3,648  of  5,764.    Elapsed: 0:05:46.\n  Batch 3,712  of  5,764.    Elapsed: 0:05:52.\n  Batch 3,776  of  5,764.    Elapsed: 0:05:58.\n  Batch 3,840  of  5,764.    Elapsed: 0:06:04.\n  Batch 3,904  of  5,764.    Elapsed: 0:06:10.\n  Batch 3,968  of  5,764.    Elapsed: 0:06:16.\n  Batch 4,032  of  5,764.    Elapsed: 0:06:22.\n  Batch 4,096  of  5,764.    Elapsed: 0:06:28.\n  Batch 4,160  of  5,764.    Elapsed: 0:06:34.\n  Batch 4,224  of  5,764.    Elapsed: 0:06:40.\n  Batch 4,288  of  5,764.    Elapsed: 0:06:46.\n  Batch 4,352  of  5,764.    Elapsed: 0:06:52.\n  Batch 4,416  of  5,764.    Elapsed: 0:06:58.\n  Batch 4,480  of  5,764.    Elapsed: 0:07:04.\n  Batch 4,544  of  5,764.    Elapsed: 0:07:10.\n  Batch 4,608  of  5,764.    Elapsed: 0:07:16.\n  Batch 4,672  of  5,764.    Elapsed: 0:07:22.\n  Batch 4,736  of  5,764.    Elapsed: 0:07:28.\n  Batch 4,800  of  5,764.    Elapsed: 0:07:34.\n  Batch 4,864  of  5,764.    Elapsed: 0:07:40.\n  Batch 4,928  of  5,764.    Elapsed: 0:07:46.\n  Batch 4,992  of  5,764.    Elapsed: 0:07:52.\n  Batch 5,056  of  5,764.    Elapsed: 0:07:58.\n  Batch 5,120  of  5,764.    Elapsed: 0:08:04.\n  Batch 5,184  of  5,764.    Elapsed: 0:08:10.\n  Batch 5,248  of  5,764.    Elapsed: 0:08:16.\n  Batch 5,312  of  5,764.    Elapsed: 0:08:22.\n  Batch 5,376  of  5,764.    Elapsed: 0:08:28.\n  Batch 5,440  of  5,764.    Elapsed: 0:08:34.\n  Batch 5,504  of  5,764.    Elapsed: 0:08:40.\n  Batch 5,568  of  5,764.    Elapsed: 0:08:46.\n  Batch 5,632  of  5,764.    Elapsed: 0:08:52.\n  Batch 5,696  of  5,764.    Elapsed: 0:08:58.\n  Batch 5,760  of  5,764.    Elapsed: 0:09:04.\n\n  Average training loss: 0.17\n  Training epcoh took: 0:09:05\n\nRunning Validation...\n  Accuracy: 0.96\n  Validation Loss: 0.17\n  Validation took: 0:00:30\n\n======== Epoch 2 / 2 ========\nTraining...\n  Batch    64  of  5,764.    Elapsed: 0:00:06.\n  Batch   128  of  5,764.    Elapsed: 0:00:12.\n  Batch   192  of  5,764.    Elapsed: 0:00:18.\n  Batch   256  of  5,764.    Elapsed: 0:00:24.\n  Batch   320  of  5,764.    Elapsed: 0:00:30.\n  Batch   384  of  5,764.    Elapsed: 0:00:36.\n  Batch   448  of  5,764.    Elapsed: 0:00:42.\n  Batch   512  of  5,764.    Elapsed: 0:00:48.\n  Batch   576  of  5,764.    Elapsed: 0:00:54.\n  Batch   640  of  5,764.    Elapsed: 0:01:00.\n  Batch   704  of  5,764.    Elapsed: 0:01:06.\n  Batch   768  of  5,764.    Elapsed: 0:01:12.\n  Batch   832  of  5,764.    Elapsed: 0:01:18.\n  Batch   896  of  5,764.    Elapsed: 0:01:24.\n  Batch   960  of  5,764.    Elapsed: 0:01:30.\n  Batch 1,024  of  5,764.    Elapsed: 0:01:36.\n  Batch 1,088  of  5,764.    Elapsed: 0:01:42.\n  Batch 1,152  of  5,764.    Elapsed: 0:01:48.\n  Batch 1,216  of  5,764.    Elapsed: 0:01:54.\n  Batch 1,280  of  5,764.    Elapsed: 0:02:00.\n  Batch 1,344  of  5,764.    Elapsed: 0:02:06.\n  Batch 1,408  of  5,764.    Elapsed: 0:02:13.\n  Batch 1,472  of  5,764.    Elapsed: 0:02:19.\n  Batch 1,536  of  5,764.    Elapsed: 0:02:25.\n  Batch 1,600  of  5,764.    Elapsed: 0:02:30.\n  Batch 1,664  of  5,764.    Elapsed: 0:02:37.\n  Batch 1,728  of  5,764.    Elapsed: 0:02:43.\n  Batch 1,792  of  5,764.    Elapsed: 0:02:49.\n  Batch 1,856  of  5,764.    Elapsed: 0:02:55.\n  Batch 1,920  of  5,764.    Elapsed: 0:03:01.\n  Batch 1,984  of  5,764.    Elapsed: 0:03:07.\n  Batch 2,048  of  5,764.    Elapsed: 0:03:13.\n  Batch 2,112  of  5,764.    Elapsed: 0:03:19.\n  Batch 2,176  of  5,764.    Elapsed: 0:03:25.\n  Batch 2,240  of  5,764.    Elapsed: 0:03:31.\n  Batch 2,304  of  5,764.    Elapsed: 0:03:37.\n  Batch 2,368  of  5,764.    Elapsed: 0:03:43.\n  Batch 2,432  of  5,764.    Elapsed: 0:03:49.\n  Batch 2,496  of  5,764.    Elapsed: 0:03:55.\n  Batch 2,560  of  5,764.    Elapsed: 0:04:01.\n  Batch 2,624  of  5,764.    Elapsed: 0:04:07.\n  Batch 2,688  of  5,764.    Elapsed: 0:04:13.\n  Batch 2,752  of  5,764.    Elapsed: 0:04:19.\n  Batch 2,816  of  5,764.    Elapsed: 0:04:25.\n  Batch 2,880  of  5,764.    Elapsed: 0:04:31.\n  Batch 2,944  of  5,764.    Elapsed: 0:04:37.\n  Batch 3,008  of  5,764.    Elapsed: 0:04:43.\n  Batch 3,072  of  5,764.    Elapsed: 0:04:49.\n  Batch 3,136  of  5,764.    Elapsed: 0:04:55.\n  Batch 3,200  of  5,764.    Elapsed: 0:05:01.\n  Batch 3,264  of  5,764.    Elapsed: 0:05:07.\n  Batch 3,328  of  5,764.    Elapsed: 0:05:13.\n  Batch 3,392  of  5,764.    Elapsed: 0:05:19.\n  Batch 3,456  of  5,764.    Elapsed: 0:05:25.\n  Batch 3,520  of  5,764.    Elapsed: 0:05:31.\n  Batch 3,584  of  5,764.    Elapsed: 0:05:37.\n  Batch 3,648  of  5,764.    Elapsed: 0:05:43.\n  Batch 3,712  of  5,764.    Elapsed: 0:05:49.\n  Batch 3,776  of  5,764.    Elapsed: 0:05:55.\n  Batch 3,840  of  5,764.    Elapsed: 0:06:01.\n  Batch 3,904  of  5,764.    Elapsed: 0:06:07.\n  Batch 3,968  of  5,764.    Elapsed: 0:06:13.\n  Batch 4,032  of  5,764.    Elapsed: 0:06:19.\n  Batch 4,096  of  5,764.    Elapsed: 0:06:26.\n  Batch 4,160  of  5,764.    Elapsed: 0:06:31.\n  Batch 4,224  of  5,764.    Elapsed: 0:06:37.\n  Batch 4,288  of  5,764.    Elapsed: 0:06:43.\n  Batch 4,352  of  5,764.    Elapsed: 0:06:49.\n  Batch 4,416  of  5,764.    Elapsed: 0:06:56.\n  Batch 4,480  of  5,764.    Elapsed: 0:07:02.\n  Batch 4,544  of  5,764.    Elapsed: 0:07:07.\n  Batch 4,608  of  5,764.    Elapsed: 0:07:13.\n  Batch 4,672  of  5,764.    Elapsed: 0:07:19.\n  Batch 4,736  of  5,764.    Elapsed: 0:07:26.\n  Batch 4,800  of  5,764.    Elapsed: 0:07:32.\n  Batch 4,864  of  5,764.    Elapsed: 0:07:38.\n  Batch 4,928  of  5,764.    Elapsed: 0:07:44.\n  Batch 4,992  of  5,764.    Elapsed: 0:07:50.\n  Batch 5,056  of  5,764.    Elapsed: 0:07:56.\n  Batch 5,120  of  5,764.    Elapsed: 0:08:02.\n  Batch 5,184  of  5,764.    Elapsed: 0:08:08.\n  Batch 5,248  of  5,764.    Elapsed: 0:08:14.\n  Batch 5,312  of  5,764.    Elapsed: 0:08:20.\n  Batch 5,376  of  5,764.    Elapsed: 0:08:26.\n  Batch 5,440  of  5,764.    Elapsed: 0:08:32.\n  Batch 5,504  of  5,764.    Elapsed: 0:08:38.\n  Batch 5,568  of  5,764.    Elapsed: 0:08:44.\n  Batch 5,632  of  5,764.    Elapsed: 0:08:50.\n  Batch 5,696  of  5,764.    Elapsed: 0:08:56.\n  Batch 5,760  of  5,764.    Elapsed: 0:09:02.\n\n  Average training loss: 0.17\n  Training epcoh took: 0:09:02\n\nRunning Validation...\n  Accuracy: 0.96\n  Validation Loss: 0.17\n  Validation took: 0:00:30\n\nTraining complete!\nTotal training took 0:19:07 (h:mm:ss)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performance On Test Set"
      ],
      "metadata": {
        "id": "B_RsKdd_kI5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = test\n",
        "\n",
        "\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "title = df.title.values\n",
        "labels = df.lables.values\n",
        "\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for t in title:\n",
        "\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        t,                      \n",
        "                        add_special_tokens = True, \n",
        "                        max_length = 18,           \n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   \n",
        "                        return_tensors = 'pt',     \n",
        "                   )\n",
        "      \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T06:07:03.821849Z",
          "iopub.execute_input": "2021-10-24T06:07:03.822151Z",
          "iopub.status.idle": "2021-10-24T06:07:44.010370Z",
          "shell.execute_reply.started": "2021-10-24T06:07:03.822118Z",
          "shell.execute_reply": "2021-10-24T06:07:44.009591Z"
        },
        "trusted": true,
        "id": "S90My561kI5q",
        "outputId": "46cedc06-44f0-4de0-cb74-ea6f86f6414d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Number of test sentences: 69,158\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "model.eval()\n",
        "\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "for batch in prediction_dataloader:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    with torch.no_grad():\n",
        "        outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    predictions.append(logits)\n",
        "    true_labels.append(label_ids)\n",
        "print('    DONE.')\n",
        "  "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T06:07:51.138050Z",
          "iopub.execute_input": "2021-10-24T06:07:51.138603Z",
          "iopub.status.idle": "2021-10-24T06:08:36.337043Z",
          "shell.execute_reply.started": "2021-10-24T06:07:51.138564Z",
          "shell.execute_reply": "2021-10-24T06:08:36.336166Z"
        },
        "trusted": true,
        "id": "WbbJihfzkI5r",
        "outputId": "886afda1-079c-4b65-ca31-f5cf4a8deeda"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Predicting labels for 69,158 test sentences...\n    DONE.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (df.lables.sum(), len(df.lables), (df.lables.sum() / len(df.lables) * 100.0)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T06:08:39.873548Z",
          "iopub.execute_input": "2021-10-24T06:08:39.874222Z",
          "iopub.status.idle": "2021-10-24T06:08:39.881783Z",
          "shell.execute_reply.started": "2021-10-24T06:08:39.874176Z",
          "shell.execute_reply": "2021-10-24T06:08:39.881027Z"
        },
        "trusted": true,
        "id": "gStrYhk0kI5r",
        "outputId": "e7fce148-f22b-4272-f31b-4c23bc04d65c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Positive samples: 2840 of 69158 (4.11%)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "import seaborn as sns\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "for i in range(len(true_labels)):\n",
        "    pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "    matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
        "    matthews_set.append(matthews)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T06:08:46.654862Z",
          "iopub.execute_input": "2021-10-24T06:08:46.655452Z",
          "iopub.status.idle": "2021-10-24T06:08:48.148443Z",
          "shell.execute_reply.started": "2021-10-24T06:08:46.655415Z",
          "shell.execute_reply": "2021-10-24T06:08:48.147583Z"
        },
        "trusted": true,
        "id": "nGsFgvBjkI5r",
        "outputId": "b52a8686-fa3f-47d3-cdf0-ae9a310585a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Calculating Matthews Corr. Coef. for each batch...\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('Total MCC: %.3f' % mcc)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T06:11:17.081305Z",
          "iopub.execute_input": "2021-10-24T06:11:17.082095Z",
          "iopub.status.idle": "2021-10-24T06:11:17.179431Z",
          "shell.execute_reply.started": "2021-10-24T06:11:17.082051Z",
          "shell.execute_reply": "2021-10-24T06:11:17.178655Z"
        },
        "trusted": true,
        "id": "x7FZ5UYakI5s",
        "outputId": "13c4d6ab-d63f-47d7-9661-88c74be0a1a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Total MCC: 0.195\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "\n",
        "output_dir = './model_save/'\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  \n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-23T14:16:21.066371Z",
          "iopub.execute_input": "2021-10-23T14:16:21.066773Z",
          "iopub.status.idle": "2021-10-23T14:16:22.06176Z",
          "shell.execute_reply.started": "2021-10-23T14:16:21.066735Z",
          "shell.execute_reply": "2021-10-23T14:16:22.06104Z"
        },
        "trusted": true,
        "id": "ZAQ8_c1VkI5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FZfSiqSYkI5s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}